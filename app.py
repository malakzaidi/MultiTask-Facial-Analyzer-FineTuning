import os
import io
import json
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image
import numpy as np
from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename
import base64
from datetime import datetime

# ================================================================
# CONFIGURATION DE L'APPLICATION
# ================================================================
app = Flask(__name__)
app.config['SECRET_KEY'] = 'celeba-multitask-secret-key-2024'
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'gif'}

# Cr√©er les dossiers n√©cessaires
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs('static/results', exist_ok=True)


# ================================================================
# MOD√àLE MULTI-T√ÇCHES
# ================================================================
class MultiTaskCelebAExact(nn.Module):
    def __init__(self, num_tasks=8):
        super().__init__()
        self.backbone = models.efficientnet_b0(weights=None)
        self.backbone.classifier = nn.Identity()
        self.heads = nn.ModuleList([
            nn.Sequential(nn.Dropout(0.5), nn.Linear(1280, 1)) for _ in range(num_tasks)
        ])

    def forward(self, x):
        f = self.backbone(x)
        return torch.cat([torch.sigmoid(head(f)) for head in self.heads], dim=1)


# Attributs cibles
TARGET_ATTRS = [
    'Male', 'Smiling', 'Young', 'Eyeglasses',
    'Wearing_Hat', 'Bald', 'Mustache', 'Wearing_Lipstick'
]

ATTRIBUTE_DESCRIPTIONS = {
    'Male': 'Genre masculin',
    'Smiling': 'Sourire visible',
    'Young': 'Personne jeune (<35 ans)',
    'Eyeglasses': 'Porte des lunettes',
    'Wearing_Hat': 'Porte un chapeau/casquette',
    'Bald': 'Chauve/peu de cheveux',
    'Mustache': 'A une moustache',
    'Wearing_Lipstick': 'Porte du rouge √† l√®vres'
}


# ================================================================
# CHARGEMENT DU MOD√àLE
# ================================================================
def load_model():
    """Charge le mod√®le pr√©-entra√Æn√©"""
    print("üîÑ Chargement du mod√®le...")

    model_path = os.path.join('models', 'BEST_FINETUNED_MODEL.pth')
    print(f"üìÅ Chemin du mod√®le: {model_path}")
    print(f"‚úÖ Mod√®le existe: {os.path.exists(model_path)}")
    if not os.path.exists(model_path):
        # Essayer un autre chemin
        model_path = '../models/BEST_FINETUNED_MODEL.pth'

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = MultiTaskCelebAExact(num_tasks=8).to(device)

    try:
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        print(f"‚úÖ Mod√®le charg√© avec succ√®s (epoch {checkpoint.get('epoch', 'N/A')})")
    except Exception as e:
        print(f"‚ùå Erreur chargement mod√®le: {e}")
        # Cr√©er un mod√®le fictif pour le d√©veloppement
        print("‚ö†Ô∏è  Utilisation d'un mod√®le fictif pour le d√©veloppement")

    return model, device


# Initialiser le mod√®le
model, device = load_model()

# Transformations pour les images
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])


# ================================================================
# FONCTIONS UTILITAIRES
# ================================================================
def allowed_file(filename):
    """V√©rifie l'extension du fichier"""
    return '.' in filename and \
        filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']


def convert_rgba_to_rgb(image):
    """Convertit une image RGBA en RGB (FIX #1)"""
    if image.mode == 'RGBA':
        # Cr√©er un fond blanc
        rgb_image = Image.new('RGB', image.size, (255, 255, 255))
        # Coller l'image RGBA en utilisant son canal alpha comme masque
        rgb_image.paste(image, mask=image.split()[3])
        return rgb_image
    elif image.mode == 'P':
        # Convertir les images en palette
        return image.convert('RGB')
    return image


def convert_numpy_types(obj):
    """Convertit les types NumPy en types Python natifs (FIX #2)"""
    if isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, (np.int_, np.intc, np.intp, np.int8,
                          np.int16, np.int32, np.int64,
                          np.uint8, np.uint16, np.uint32, np.uint64)):
        return int(obj)
    elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    return obj


def save_image(image_data):
    """Sauvegarde une image √† partir de donn√©es base64 ou fichier"""
    if isinstance(image_data, str) and 'base64' in image_data:
        # D√©coder l'image base64
        header, encoded = image_data.split(",", 1)
        image_bytes = base64.b64decode(encoded)
        image = Image.open(io.BytesIO(image_bytes))
    else:
        # Ouvrir l'image normale
        image = Image.open(image_data)

    # Convertir RGBA en RGB si n√©cessaire (FIX #1)
    image = convert_rgba_to_rgb(image)

    # G√©n√©rer un nom de fichier unique
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"celeba_{timestamp}.jpg"
    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)

    # Sauvegarder l'image en JPEG
    image.save(filepath, 'JPEG', quality=90)
    return filename, filepath


def preprocess_image(image_path):
    """Pr√©traite une image pour le mod√®le"""
    try:
        image = Image.open(image_path).convert('RGB')

        # Sauvegarder une version redimensionn√©e pour l'affichage
        display_size = (300, 300)
        display_image = image.copy()
        display_image.thumbnail(display_size, Image.Resampling.LANCZOS)

        # Appliquer les transformations pour le mod√®le
        input_tensor = transform(image).unsqueeze(0)
        return input_tensor, display_image
    except Exception as e:
        print(f"‚ùå Erreur pr√©traitement image: {e}")
        return None, None


def predict_attributes(image_tensor):
    """Pr√©dit les attributs pour une image"""
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        outputs = model(image_tensor)
        probabilities = outputs.cpu().numpy()[0]

    return probabilities


def generate_confidence_bar(probability):
    """G√©n√®re une barre de confiance HTML"""
    # Convertir numpy types (FIX #2)
    probability = float(probability)
    width = int(probability * 100)
    color_class = "high-confidence" if probability > 0.7 else "medium-confidence" if probability > 0.5 else "low-confidence"

    return f'''
    <div class="confidence-bar">
        <div class="confidence-fill {color_class}" style="width: {width}%"></div>
        <span class="confidence-text">{probability:.2%}</span>
    </div>
    '''


def generate_result_card(attribute, probability, description):
    """G√©n√®re une carte de r√©sultat HTML"""
    # Convertir numpy types (FIX #2)
    probability = float(probability)
    is_present = probability > 0.5
    status = "present" if is_present else "absent"
    icon = "‚úì" if is_present else "‚úó"
    color = "success" if is_present else "secondary"

    confidence_bar = generate_confidence_bar(probability)

    return f'''
    <div class="col-md-6 col-lg-4">
        <div class="attribute-card {status}">
            <div class="attribute-header">
                <h5>{attribute}</h5>
                <span class="attribute-status badge bg-{color}">{icon} {status.capitalize()}</span>
            </div>
            <p class="attribute-description">{description}</p>
            <div class="confidence-section">
                <small class="text-muted">Confiance:</small>
                {confidence_bar}
            </div>
            <div class="attribute-details">
                <small>Probabilit√©: <strong>{probability:.2%}</strong></small>
                <small>Seuil: <strong>50%</strong></small>
            </div>
        </div>
    </div>
    '''


# ================================================================
# ROUTES FLASK
# ================================================================
@app.route('/')
def index():
    """Page d'accueil"""
    return render_template('index.html',
                           attributes=TARGET_ATTRS,
                           descriptions=ATTRIBUTE_DESCRIPTIONS)


@app.route('/about')
def about():
    """Page √Ä propos"""
    return render_template('about.html')


@app.route('/upload', methods=['POST'])
def upload_file():
    """G√®re l'upload d'image (FIXED VERSION)"""
    if 'file' not in request.files:
        return jsonify({'error': 'Aucun fichier s√©lectionn√©'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'Nom de fichier vide'}), 400

    if file and allowed_file(file.filename):
        try:
            # Sauvegarder l'image (avec conversion RGBA->RGB automatique)
            filename, filepath = save_image(file)

            # Pr√©traiter l'image
            input_tensor, display_image = preprocess_image(filepath)
            if input_tensor is None:
                return jsonify({'error': 'Erreur de traitement de l\'image'}), 500

            # Sauvegarder l'image d'affichage
            display_filename = f"display_{filename}"
            display_path = os.path.join('static/results', display_filename)

            # Convertir RGBA en RGB si n√©cessaire (FIX #1)
            display_image = convert_rgba_to_rgb(display_image)
            display_image.save(display_path, 'JPEG', quality=90)

            # Faire la pr√©diction
            probabilities = predict_attributes(input_tensor)

            # Pr√©parer les r√©sultats (FIX #2: Convertir tous les types numpy)
            results = []
            for attr, prob, desc in zip(TARGET_ATTRS, probabilities, ATTRIBUTE_DESCRIPTIONS.values()):
                # Convertir les types numpy en types Python natifs
                prob_float = convert_numpy_types(prob)
                is_present = convert_numpy_types(prob > 0.5)

                results.append({
                    'attribute': attr,
                    'probability': prob_float,
                    'description': desc,
                    'present': is_present,
                    'confidence_bar': generate_confidence_bar(prob_float),
                    'card_html': generate_result_card(attr, prob_float, desc)
                })

            # Calculer le temps de traitement
            processing_time = "0.5s"  # En temps r√©el, mesurer avec time.time()

            # Convertir la moyenne numpy en float (FIX #2)
            avg_confidence = float(np.mean([r['probability'] for r in results]))

            return jsonify({
                'success': True,
                'filename': filename,
                'display_image': f'/static/results/{display_filename}',
                'results': results,
                'processing_time': processing_time,
                'summary': {
                    'total_attributes': len(TARGET_ATTRS),
                    'present_count': sum(1 for r in results if r['present']),
                    'avg_confidence': avg_confidence
                }
            })

        except Exception as e:
            print(f"‚ùå Erreur lors du traitement: {e}")
            import traceback
            traceback.print_exc()
            return jsonify({'error': f'Erreur de traitement: {str(e)}'}), 500

    return jsonify({'error': 'Type de fichier non autoris√©'}), 400


@app.route('/api/predict', methods=['POST'])
def api_predict():
    """API pour pr√©dictions (format JSON) - FIXED VERSION"""
    if 'image' not in request.files and 'image_url' not in request.json:
        return jsonify({'error': 'Aucune image fournie'}), 400

    try:
        if 'image' in request.files:
            file = request.files['image']
            _, filepath = save_image(file)
        else:
            # T√©l√©charger depuis une URL (impl√©mentation simplifi√©e)
            import requests
            response = requests.get(request.json['image_url'])
            filepath = f"uploads/temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
            with open(filepath, 'wb') as f:
                f.write(response.content)

        # Pr√©traiter et pr√©dire
        input_tensor, _ = preprocess_image(filepath)
        probabilities = predict_attributes(input_tensor)

        # Formater la r√©ponse (FIX #2: Convertir tous les types numpy)
        predictions = {}
        for attr, prob in zip(TARGET_ATTRS, probabilities):
            prob_float = convert_numpy_types(prob)
            is_present = convert_numpy_types(prob > 0.5)

            predictions[attr] = {
                'present': is_present,
                'probability': prob_float,
                'confidence': 'high' if prob_float > 0.8 else 'medium' if prob_float > 0.6 else 'low'
            }

        return jsonify({
            'success': True,
            'predictions': predictions,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        print(f"‚ùå Erreur API: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/model_info')
def api_model_info():
    """Retourne les informations du mod√®le"""
    return jsonify({
        'model_name': 'MultiTask CelebA EfficientNet-B0',
        'attributes': TARGET_ATTRS,
        'attribute_descriptions': ATTRIBUTE_DESCRIPTIONS,
        'input_size': '224x224 pixels',
        'framework': 'PyTorch',
        'performance': {
            'avg_accuracy': '94.5%',
            'best_auc': '0.9975 (Eyeglasses)'
        }
    })


@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """Servir les images upload√©es"""
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)


# ================================================================
# PAGES D'ERREUR (FIX #3)
# ================================================================
@app.errorhandler(404)
def not_found_error(error):
    """Gestion des erreurs 404"""
    try:
        return render_template('404.html'), 404
    except:
        # Si le template n'existe pas, retourner une r√©ponse simple
        return '''
        <html>
        <head><title>404 - Page non trouv√©e</title></head>
        <body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1>404</h1>
            <h2>Page non trouv√©e</h2>
            <p>La page que vous recherchez n'existe pas.</p>
            <p><a href="/">‚Üê Retour √† l'accueil</a></p>
        </body>
        </html>
        ''', 404


@app.errorhandler(500)
def internal_error(error):
    """Gestion des erreurs 500"""
    try:
        return render_template('500.html'), 500
    except:
        # Si le template n'existe pas, retourner une r√©ponse simple
        return '''
        <html>
        <head><title>500 - Erreur serveur</title></head>
        <body style="font-family: Arial; text-align: center; padding: 50px;">
            <h1>500</h1>
            <h2>Erreur serveur</h2>
            <p>Une erreur s'est produite. Veuillez r√©essayer.</p>
            <p><a href="/">‚Üê Retour √† l'accueil</a></p>
        </body>
        </html>
        ''', 500


# ================================================================
# LANCEMENT DE L'APPLICATION
# ================================================================
if __name__ == '__main__':
    print("=" * 60)
    print("üöÄ APPLICATION FLASK - D√âTECTION D'ATTRIBUTS CELEBA")
    print("=" * 60)
    print(f"üìÅ Dossier d'upload: {app.config['UPLOAD_FOLDER']}")
    print(f"üéØ Attributs d√©tect√©s: {', '.join(TARGET_ATTRS)}")
    print(f"‚ö° Device: {device}")
    print("=" * 60)
    print("‚úÖ FIXES APPLIQU√âS:")
    print("   1. Conversion RGBA ‚Üí RGB pour JPEG")
    print("   2. Conversion numpy.bool_ ‚Üí bool Python")
    print("   3. Gestion des erreurs 404/500 avec fallback")
    print("=" * 60)
    print("üåê Application accessible sur: http://localhost:5000")
    print("=" * 60)

    app.run(debug=True, host='0.0.0.0', port=5000)